# Input section: Consumes data from Kafka
input:
  kafka:
    addresses: ["${KAFKA_BROKERS}"]
    topics: ["${KAFKA_TOPICS}"]
    consumer_group: "${KAFKA_CONSUMER_GROUP}"

# Pipeline section: Processes and transforms data
pipeline:
  processors:
    - mapping: |
        root.id = uuid_v4()
        root.timestamp = now()
        root.data = content().uppercase()
    - switch:
        - check: "\"${LOG_LEVEL}\" == \"DEBUG\""
          processors:
            - log:
                level: "${LOG_LEVEL}"
                message: 'Inserting record into SQL: ${! json() }'
    # Count all incoming messages
    - metric:
        type: counter
        name: kafka_postgres_messages_total
        value: "1"
        labels:
          service: "redpanda"
          pipeline: "kafka_to_postgres"
    
    # Count dropped messages (when insert fails)
    - catch:
        - metric:
            type: counter
            name: kafka_postgres_messages_dropped
            value: "1"
            labels:
              service: "redpanda"
              pipeline: "kafka_to_postgres"

# Output section: Routes data to multiple destinations
output:
  fallback:
    - retry:
        max_retries: 3
        backoff:
          initial_interval: 500ms
        output:
          sql_insert:
            driver: postgres
            dsn: "${POSTGRES_URL}"
            table: "${POSTGRES_TABLE}"
            columns: ["id", "timestamp", "data"]
            args_mapping: |
              root = [
                this.id,
                this.timestamp,
                this.data
              ]
            suffix: ON CONFLICT (data) DO NOTHING
            max_in_flight: 1

    - redpanda:
        seed_brokers: ["${KAFKA_BROKERS}"]
        topic: "failed-messages"
        compression: gzip

    - stdout: {}

# Logger section: Controls logging verbosity
logger:
  level: "${LOG_LEVEL}"

# Metrics section: Exposes metrics directly via HTTP
http:
  address: "127.0.0.1:4195"

metrics:
  prometheus:
    use_histogram_timing: true